{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dabc4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comparing audio transcription api for speed and cost (speech to text)\n",
    "\n",
    "#This require importing a cesar.wav file on colab and setting api key below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1e0e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Required for colab \n",
    "!pip install -U \"mistralai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0e71b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Used directly by openai python client\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPEN_API_KEY\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb58be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(\"cesar.wav\", \"rb\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"gpt-4o-transcribe\",\n",
    "  file=audio_file\n",
    ")\n",
    "\n",
    "print (transcript.text)\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "print(f\"{duration.total_seconds():.3f}\")\n",
    "print(f\"Number of tokens: {transcript.usage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde74d21",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"voxtral-mini-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "with open(\"cesar.wav\", \"rb\") as f:\n",
    "    transcription_response = client.audio.transcriptions.complete(\n",
    "        model=model,\n",
    "        file={\n",
    "            \"content\": f,\n",
    "            \"file_name\": \"cesar.wav\"\n",
    "        },\n",
    "        ## language=\"fr\"\n",
    "    )\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "print(f\"{duration.total_seconds():.3f}\")\n",
    "\n",
    "print (transcription_response)\n",
    "print(transcription_response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b9ef6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Result for a 12 seconds audio\n",
    "# openai gpt-4o-transcribe (fastest than whisper-1 and other from openai) : 3 to 5 seconds\n",
    "# mistral voxtral-mini-latest : 1 second\n",
    "# In our test, Mistral model is 4 times faster than OpenAI (which is 2x faster than original file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
